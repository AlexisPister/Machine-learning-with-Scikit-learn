{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Techniques d'apprentissage automatique\n",
    "## TP2 - Apprentissage supervisé avec python\n",
    "### Alexis Pister"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.nan,suppress=True)\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4375,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1216.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        3159.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data processing\n",
    "df = pd.read_csv('./credit_scoring.csv', sep=\";\")\n",
    "data = df.values\n",
    "colonnes = df.columns\n",
    "\n",
    "# Variables caracteristiques\n",
    "X = data[:,:-1]\n",
    "# Labels a predire\n",
    "Y = data[:,-1]\n",
    "\n",
    "# Analyse des données\n",
    "print(np.shape(Y))\n",
    "plt.hist(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données comporte 4375 échantillons, avec 1216 négatifs (0) et 3159 positifs (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[183 214]\n",
      " [201 846]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.46      0.47       397\n",
      "         1.0       0.80      0.81      0.80      1047\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      1444\n",
      "   macro avg       0.64      0.63      0.64      1444\n",
      "weighted avg       0.71      0.71      0.71      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Separation en train et test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Arbre CART\n",
    "# Classifier initialisation\n",
    "classifier = DecisionTreeClassifier(random_state=1)\n",
    "# training\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Results of classification (metrics)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[124 273]\n",
      " [131 916]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.31      0.38       397\n",
      "         1.0       0.77      0.87      0.82      1047\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      1444\n",
      "   macro avg       0.63      0.59      0.60      1444\n",
      "weighted avg       0.69      0.72      0.70      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# K plus proches voisins\n",
    "\n",
    "# Classifier initialisation\n",
    "kppv = KNeighborsClassifier(n_neighbors=5)\n",
    "# training\n",
    "kppv.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "y_pred = kppv.predict(X_test)\n",
    "\n",
    "# Results of classification (metrics)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans notre cas d'étude où on recherche des profils qui peuvent rembourser des crédit, il parait plus judicieux de comparer la précision que le rappel. En effet, si la banque donne un crédit non rembousé, elle est beaucoup plus perdante que si elle gagne un crédit en plus. On cherche donc plus la sécurité et donc la précision que la quantité associée au rappel.\n",
    "\n",
    "L'arbre CART et les k-plus-proche-voisins donnent respectivement un score-F1 (correspondant ici à l'accuracy) pondéré par les proportions des 2 classes de 0.71 et 0.70, et une précision pondérée de 0.71 et 0.69.\n",
    "\n",
    "Les 2 classifieurs donnent donc des résultats très proche et il est dur de les différencier. A choisir, on favoriserai tout de même l'arbre CART donnant un score et une précision un peu plus important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard normalisation\n",
      "Arbre CART\n",
      "[[184 213]\n",
      " [202 845]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.46      0.47       397\n",
      "         1.0       0.80      0.81      0.80      1047\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      1444\n",
      "   macro avg       0.64      0.64      0.64      1444\n",
      "weighted avg       0.71      0.71      0.71      1444\n",
      "\n",
      "KPPV\n",
      "[[179 218]\n",
      " [147 900]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.45      0.50       397\n",
      "         1.0       0.81      0.86      0.83      1047\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      1444\n",
      "   macro avg       0.68      0.66      0.66      1444\n",
      "weighted avg       0.73      0.75      0.74      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On normalise les données\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Standard normalisation\n",
    "print('Standard normalisation')\n",
    "Xnorm = StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# Separation en train et test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xnorm, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Arbre CART\n",
    "print('Arbre CART')\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# kppv\n",
    "print('KPPV')\n",
    "kppv.fit(X_train, y_train)\n",
    "y_pred = kppv.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax normalisation\n",
      "Arbre CART\n",
      "[[183 214]\n",
      " [202 845]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.46      0.47       397\n",
      "         1.0       0.80      0.81      0.80      1047\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      1444\n",
      "   macro avg       0.64      0.63      0.64      1444\n",
      "weighted avg       0.71      0.71      0.71      1444\n",
      "\n",
      "KPPV\n",
      "[[170 227]\n",
      " [139 908]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.43      0.48       397\n",
      "         1.0       0.80      0.87      0.83      1047\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      1444\n",
      "   macro avg       0.68      0.65      0.66      1444\n",
      "weighted avg       0.73      0.75      0.74      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MinMax normalisation\n",
    "print('MinMax normalisation')\n",
    "Xnorm = MinMaxScaler().fit(X).transform(X)\n",
    "\n",
    "# Separation en train et test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xnorm, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Arbre CART\n",
    "print('Arbre CART')\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# kpv\n",
    "print('KPPV')\n",
    "kppv.fit(X_train, y_train)\n",
    "y_pred = kppv.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le classifieur CART, il semble que normaliser les données ne change pas les metriques de classification, autant pour une normalisation normale que Min-Max. Cependant, cela améliore la classification pour la technique des k-plus-proche-voisins.\n",
    "La précision et le score f1 pondérés passent respectivement de 0.69 et 0.70 à 0.73 et 0.74 après la normalisation (autant pour la normalisation normale et MinMax), ce qui donne une classification meilleurs que l'arbre de décision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 : Ajout de l'ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance expliquée par les composantes de l'acp :  [0.3132101  0.23599    0.16118877 0.13889973 0.05277771 0.04561142\n",
      " 0.01634432 0.01459562 0.01082235 0.0064157  0.00173251 0.00129816\n",
      " 0.00111361]\n",
      "Arbre CART\n",
      "[[204 193]\n",
      " [209 838]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.51      0.50       397\n",
      "         1.0       0.81      0.80      0.81      1047\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      1444\n",
      "   macro avg       0.65      0.66      0.66      1444\n",
      "weighted avg       0.73      0.72      0.72      1444\n",
      "\n",
      "KPPV\n",
      "[[171 226]\n",
      " [140 907]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.43      0.48       397\n",
      "         1.0       0.80      0.87      0.83      1047\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      1444\n",
      "   macro avg       0.68      0.65      0.66      1444\n",
      "weighted avg       0.73      0.75      0.74      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# PCA\n",
    "acp = PCA(svd_solver='full')\n",
    "Xacp = acp.fit_transform(Xnorm)\n",
    "\n",
    "# On va garder les 4 premieres dimensions de l'acp qui expliquent 90% de l'information\n",
    "print(\"Variance expliquée par les composantes de l'acp : \", acp.explained_variance_ratio_)\n",
    "\n",
    "# On rajoute les 4 nouvelles dimensions au jeu de données\n",
    "Xnew = np.hstack((Xnorm, Xacp[:,:4]))\n",
    "\n",
    "# Separation en train et test set\n",
    "X_train_pca, X_test_pca, y_train, y_test = train_test_split(Xnew, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Arbre CART\n",
    "print('Arbre CART')\n",
    "classifier.fit(X_train_pca, y_train)\n",
    "y_pred = classifier.predict(X_test_pca)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# kpv\n",
    "print('KPPV')\n",
    "kppv.fit(X_train_pca, y_train)\n",
    "y_pred = kppv.predict(X_test_pca)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que l'ajout des 4 dimensions de l'ACP augmente la précision, le rappel et le score pondérés de 1% pour l'arbre de décision. On peut considérer que dans un sens l'ACP rajoute une part d'informations au données qui amélore la classification, même si elle se base sur les variables initiales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Income' 'Price' 'Seniority' 'Amount' 'Age' 'Assets' 'Expenses' 'Records'\n",
      " 'Time' 'Job' 'Debt' 'Home' 'Marital']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "colonnes = np.array(colonnes)\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(Xnorm, Y)\n",
    "importances=clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],axis=0)\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "features = colonnes\n",
    "print(features[sorted_idx])\n",
    "padding = np.arange(X_train.size/len(X_train)) + 0.5\n",
    "plt.barh(padding, importances[sorted_idx],xerr=std[sorted_idx], align='center')\n",
    "plt.yticks(padding, features[sorted_idx])\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.title(\"Variable Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# On determine le nombre de variables a garder\n",
    "KNN=KNeighborsClassifier(n_neighbors=5)\n",
    "scores=np.zeros(X_train_pca.shape[1]+1)\n",
    "for f in np.arange(0, X_train_pca.shape[1]+1):\n",
    "    X1_f = X_train_pca[:,sorted_idx[:f+1]]\n",
    "    X2_f = X_test_pca[:,sorted_idx[:f+1]]\n",
    "    KNN.fit(X1_f,y_train)\n",
    "    YKNN=KNN.predict(X2_f)\n",
    "    scores[f]=np.round(accuracy_score(y_test,YKNN),3)\n",
    "plt.plot(scores)\n",
    "plt.xlabel(\"Nombre de Variables\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Evolution de l'accuracy en fonction des variables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir à l'aide du graphique qu'on obtient une accuracy la plus grande de 0.75 en choisissant 7 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'splitter': 'random', 'criterion': 'entropy', 'max_depth': 5}\n",
      "0.7703855339474582\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# On va faire une recherche des meilleurs parametres pour l'arbre de decision et les KPPV\n",
    "\n",
    "parameters = {'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random'], 'max_depth':[None,2,3,4,5,6,7]}\n",
    "tree = DecisionTreeClassifier(random_state=1)\n",
    "clf = GridSearchCV(tree, parameters)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur les paramètres étudiées (criterion, splitter et max_depth), le meilleurs classifieur est obtenu avec la fonction d'entropy comme fonction de qualité, une stratégie aléatoire pour choisir la séparation à chaque noeud, et une longueur maximal de l'arbre de 5. Un score de 0.77 est alors obtenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'p': 2}\n",
      "0.7683384510406005\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_neighbors':[3,4,5,6,7,8,9,10],\n",
    "              'weights':['uniform', 'distance'],\n",
    "              'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'p':[1,2]}\n",
    "kppv = KNeighborsClassifier()\n",
    "clf = GridSearchCV(kppv, parameters)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les k-plus-proche-voisins, le meilleurs score de 0.76 est obtenu avec k = 7, la distance euclidienne utilisée, des poids inverses, et un algorithme de calcul des plus proches voisins décidé automatiquement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 : Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.46      0.45       397\n",
      "         1.0       0.79      0.78      0.78      1047\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      1444\n",
      "   macro avg       0.62      0.62      0.62      1444\n",
      "weighted avg       0.70      0.69      0.69      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('Normalization', MinMaxScaler()),\n",
    "    ('feats', FeatureUnion([\n",
    "        ('PCA', PCA(n_components = 0.90, svd_solver='full'))\n",
    "    ])),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=1))  # classifier\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "# train the classifier\n",
    "fit = pipeline.fit(X_train, y_train)\n",
    "# test the classifier\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.41      0.47       397\n",
      "         1.0       0.80      0.87      0.83      1047\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      1444\n",
      "   macro avg       0.67      0.64      0.65      1444\n",
      "weighted avg       0.73      0.74      0.73      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KPPV\n",
    "pipeline = Pipeline([\n",
    "    ('Normalization', MinMaxScaler()),\n",
    "    ('feats', FeatureUnion([\n",
    "        ('PCA', PCA(n_components = 0.90, svd_solver='full'))\n",
    "    ])),\n",
    "    ('kppv', KNeighborsClassifier(n_neighbors=7))\n",
    "])\n",
    "\n",
    "# train the classifier\n",
    "fit = pipeline.fit(X_train, y_train)\n",
    "# test the classifier\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats ne sont pas exactement les mêmes. Cela doit venir de la normalisation qui se fait ici sur les jeux d'entrainement et les jeux de test de manère séparé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8 : comparaison de classifieurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= MLP =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 26.064749240875244 secondes\n",
      "Accuracy for MLP is: 0.790 +/- 0.019\n",
      "AUC for MLP is: 0.832 +/- 0.019\n",
      "precision for MLP is: 0.834 +/- 0.025\n",
      "\n",
      "\n",
      "======= ID3 =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 1.469139575958252 secondes\n",
      "Accuracy for ID3 is: 0.716 +/- 0.014\n",
      "AUC for ID3 is: 0.650 +/- 0.020\n",
      "precision for ID3 is: 0.806 +/- 0.022\n",
      "\n",
      "\n",
      "======= ADABOOST =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 7.646195888519287 secondes\n",
      "Accuracy for ADABOOST is: 0.792 +/- 0.017\n",
      "AUC for ADABOOST is: 0.829 +/- 0.017\n",
      "precision for ADABOOST is: 0.826 +/- 0.018\n",
      "\n",
      "\n",
      "======= BAGGING =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 30.388845682144165 secondes\n",
      "Accuracy for BAGGING is: 0.778 +/- 0.026\n",
      "AUC for BAGGING is: 0.819 +/- 0.018\n",
      "precision for BAGGING is: 0.823 +/- 0.026\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.42798542976379395 secondes\n",
      "Accuracy for KPPV is: 0.762 +/- 0.014\n",
      "AUC for KPPV is: 0.751 +/- 0.019\n",
      "precision for KPPV is: 0.806 +/- 0.021\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 8.60301923751831 secondes\n",
      "Accuracy for RF is: 0.781 +/- 0.020\n",
      "AUC for RF is: 0.819 +/- 0.020\n",
      "precision for RF is: 0.823 +/- 0.021\n",
      "\n",
      "\n",
      "======= CART =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 1.1187245845794678 secondes\n",
      "Accuracy for CART is: 0.720 +/- 0.017\n",
      "AUC for CART is: 0.659 +/- 0.026\n",
      "precision for CART is: 0.812 +/- 0.025\n",
      "\n",
      "\n",
      "======= NB =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.09291934967041016 secondes\n",
      "Accuracy for NB is: 0.761 +/- 0.012\n",
      "AUC for NB is: 0.793 +/- 0.019\n",
      "precision for NB is: 0.846 +/- 0.025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier    \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import time\n",
    "\n",
    "# Differents classifieurs\n",
    "clfs = {\n",
    "'NB': GaussianNB(),\n",
    "'CART': DecisionTreeClassifier(random_state=1),\n",
    "'RF': RandomForestClassifier(n_estimators=50, random_state=1),\n",
    "'ID3': DecisionTreeClassifier(criterion = 'entropy', random_state=1),\n",
    "'MLP': MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(20,10),random_state=1),\n",
    "'KPPV': KNeighborsClassifier(n_neighbors=7),\n",
    "'BAGGING': BaggingClassifier(n_estimators=50,random_state=1),\n",
    "'ADABOOST': AdaBoostClassifier(n_estimators=50, random_state=1)\n",
    "}\n",
    "\n",
    "# Fonction de test des différents classifieurs\n",
    "def run_classifiers(clfs,X,Y):\n",
    "    Xnorm = MinMaxScaler().fit(X).transform(X)\n",
    "    acp = PCA(n_components=0.90, svd_solver='full')\n",
    "    Xacp = acp.fit_transform(Xnorm)\n",
    "    Xproc = np.hstack((Xnorm, Xacp[:,:]))\n",
    "    \n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    for i in clfs:\n",
    "        clf = clfs[i]\n",
    "        print(\"\\n\\n======= {0} =======\".format(i))\n",
    "        start_time = time.time()\n",
    "        cv_acc = cross_val_score(clf, Xproc, Y, cv=kf)\n",
    "        print('\\nTemps d\\'exécution d\\'un cross val : %s secondes'%(time.time() - start_time))\n",
    "        cv_auc = cross_val_score(clf, Xproc, Y, cv=kf, scoring='roc_auc')\n",
    "        cv_prec = cross_val_score(clf, Xproc, Y, cv=kf, scoring='precision')\n",
    "        print(\"Accuracy for {0} is: {1:.3f} +/- {2:.3f}\".format(i, np.mean(cv_acc), np.std(cv_acc)))\n",
    "        print(\"AUC for {0} is: {1:.3f} +/- {2:.3f}\".format(i, cv_auc.mean(), cv_auc.std()))\n",
    "        print(\"precision for {0} is: {1:.3f} +/- {2:.3f}\".format(i, cv_prec.mean(), cv_prec.std()))\n",
    "\n",
    "run_classifiers(clfs, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les meilleurs classifieur semble être les méthodes ensemblistes (random forest et bagging) ainsi que le MultiLayerPerceptron. Cependant, si on regarde juste la précision, c'est le classifieur Bayésien qui donne le meilleurs résultat avec une précision de 0.846."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Apprentissage supervisé : Données hétérogènes\n",
    "\n",
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(666,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([367., 299.]), array([0. , 0.5, 1. ]), <a list of 2 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = pd.read_csv('./credit.data',sep='\\t', header=None)\n",
    "colonnes = df2.columns\n",
    "values = df2.values\n",
    "\n",
    "# Variables caracteristiques\n",
    "X2 = values[:,:-1]\n",
    "# Labels a predire\n",
    "Y2 = values[:,-1]\n",
    "\n",
    "X2[X2 == '?']=np.nan\n",
    "\n",
    "# Converti en float\n",
    "X2_num = X2[:,(1,2,7,10,13,14)]\n",
    "X2_num = X2_num.astype(np.float32)\n",
    "\n",
    "# Supprimer les nans\n",
    "mask = np.any(np.isnan(X2_num), axis=1)\n",
    "X2_num=X2_num[~mask]\n",
    "Y2 = Y2[~mask]\n",
    "\n",
    "# Converti\n",
    "Y2[Y2 == '+'] = 1\n",
    "Y2[Y2 == '-'] = 0\n",
    "\n",
    "# Analyse des données\n",
    "print(np.shape(Y2))\n",
    "Y2 = Y2.astype(np.int)\n",
    "plt.hist(Y2, bins=2,rwidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'échantillon comporte désormais 666 individus après traitement, avec 367 crédits non accordés (0) et 299 accordés (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= MLP =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 4.2922303676605225 secondes\n",
      "Accuracy for MLP is: 0.746 +/- 0.046\n",
      "AUC for MLP is: 0.775 +/- 0.047\n",
      "precision for MLP is: 0.729 +/- 0.050\n",
      "\n",
      "\n",
      "======= ID3 =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.10726642608642578 secondes\n",
      "Accuracy for ID3 is: 0.700 +/- 0.040\n",
      "AUC for ID3 is: 0.699 +/- 0.041\n",
      "precision for ID3 is: 0.662 +/- 0.057\n",
      "\n",
      "\n",
      "======= ADABOOST =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 1.8083453178405762 secondes\n",
      "Accuracy for ADABOOST is: 0.776 +/- 0.040\n",
      "AUC for ADABOOST is: 0.838 +/- 0.055\n",
      "precision for ADABOOST is: 0.776 +/- 0.082\n",
      "\n",
      "\n",
      "======= BAGGING =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 2.425422191619873 secondes\n",
      "Accuracy for BAGGING is: 0.778 +/- 0.038\n",
      "AUC for BAGGING is: 0.831 +/- 0.044\n",
      "precision for BAGGING is: 0.785 +/- 0.073\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.04648280143737793 secondes\n",
      "Accuracy for KPPV is: 0.700 +/- 0.060\n",
      "AUC for KPPV is: 0.725 +/- 0.063\n",
      "precision for KPPV is: 0.706 +/- 0.109\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 1.6240689754486084 secondes\n",
      "Accuracy for RF is: 0.779 +/- 0.031\n",
      "AUC for RF is: 0.845 +/- 0.042\n",
      "precision for RF is: 0.789 +/- 0.050\n",
      "\n",
      "\n",
      "======= CART =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.06854772567749023 secondes\n",
      "Accuracy for CART is: 0.719 +/- 0.066\n",
      "AUC for CART is: 0.718 +/- 0.070\n",
      "precision for CART is: 0.682 +/- 0.084\n",
      "\n",
      "\n",
      "======= NB =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.0376734733581543 secondes\n",
      "Accuracy for NB is: 0.722 +/- 0.035\n",
      "AUC for NB is: 0.793 +/- 0.065\n",
      "precision for NB is: 0.834 +/- 0.123\n",
      "\n",
      "\n",
      "======= KNN =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.04731559753417969 secondes\n",
      "Accuracy for KNN is: 0.694 +/- 0.066\n",
      "AUC for KNN is: 0.737 +/- 0.063\n",
      "precision for KNN is: 0.736 +/- 0.120\n"
     ]
    }
   ],
   "source": [
    "# Evaluation des modeles sans la normalisation\n",
    "def run_classifiers(clfs,X,Y):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    for i in clfs:\n",
    "        clf = clfs[i]\n",
    "        print(\"\\n\\n======= {0} =======\".format(i))\n",
    "        start_time = time.time()\n",
    "        cv_acc = cross_val_score(clf, X, Y, cv=kf)\n",
    "        print('\\nTemps d\\'exécution d\\'un cross val : %s secondes'%(time.time() - start_time))\n",
    "        cv_auc = cross_val_score(clf, X, Y, cv=kf, scoring='roc_auc')\n",
    "        cv_prec = cross_val_score(clf, X, Y, cv=kf, scoring='precision')\n",
    "        print(\"Accuracy for {0} is: {1:.3f} +/- {2:.3f}\".format(i, np.mean(cv_acc), np.std(cv_acc)))\n",
    "        print(\"AUC for {0} is: {1:.3f} +/- {2:.3f}\".format(i, cv_auc.mean(), cv_auc.std()))\n",
    "        print(\"precision for {0} is: {1:.3f} +/- {2:.3f}\".format(i, cv_prec.mean(), cv_prec.std()))\n",
    "\n",
    "        \n",
    "run_classifiers(clfs, X2_num, Y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'évaluation globale d'un classifieur peut se faire à l'aide de l'aire sous la courbe ROC appelée AUC. Il semble que ce sont les méthodes ensemblistes qui donnent les meilleurs résultats si on ne normalise pas les données (Random forests, ADABOOST et bagging). On obtient jusqu'à une AUC de 0.845 avec avec les Random Forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= MLP =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 4.317027807235718 secondes\n",
      "Accuracy for MLP is: 0.733 +/- 0.044\n",
      "AUC for MLP is: 0.780 +/- 0.040\n",
      "precision for MLP is: 0.709 +/- 0.063\n",
      "\n",
      "\n",
      "======= ID3 =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.1060800552368164 secondes\n",
      "Accuracy for ID3 is: 0.698 +/- 0.040\n",
      "AUC for ID3 is: 0.697 +/- 0.040\n",
      "precision for ID3 is: 0.661 +/- 0.058\n",
      "\n",
      "\n",
      "======= ADABOOST =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 1.8465638160705566 secondes\n",
      "Accuracy for ADABOOST is: 0.776 +/- 0.040\n",
      "AUC for ADABOOST is: 0.838 +/- 0.055\n",
      "precision for ADABOOST is: 0.776 +/- 0.082\n",
      "\n",
      "\n",
      "======= BAGGING =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 2.4674289226531982 secondes\n",
      "Accuracy for BAGGING is: 0.778 +/- 0.038\n",
      "AUC for BAGGING is: 0.831 +/- 0.045\n",
      "precision for BAGGING is: 0.785 +/- 0.073\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.06613397598266602 secondes\n",
      "Accuracy for KPPV is: 0.755 +/- 0.045\n",
      "AUC for KPPV is: 0.804 +/- 0.047\n",
      "precision for KPPV is: 0.805 +/- 0.068\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 1.8001110553741455 secondes\n",
      "Accuracy for RF is: 0.784 +/- 0.031\n",
      "AUC for RF is: 0.845 +/- 0.040\n",
      "precision for RF is: 0.791 +/- 0.052\n",
      "\n",
      "\n",
      "======= CART =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.06916570663452148 secondes\n",
      "Accuracy for CART is: 0.719 +/- 0.064\n",
      "AUC for CART is: 0.718 +/- 0.066\n",
      "precision for CART is: 0.683 +/- 0.080\n",
      "\n",
      "\n",
      "======= NB =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.03782510757446289 secondes\n",
      "Accuracy for NB is: 0.722 +/- 0.035\n",
      "AUC for NB is: 0.793 +/- 0.065\n",
      "precision for NB is: 0.834 +/- 0.123\n",
      "\n",
      "\n",
      "======= KNN =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.0573885440826416 secondes\n",
      "Accuracy for KNN is: 0.739 +/- 0.032\n",
      "AUC for KNN is: 0.806 +/- 0.050\n",
      "precision for KNN is: 0.841 +/- 0.057\n"
     ]
    }
   ],
   "source": [
    "# On normalise maintenant les données\n",
    "def run_classifiers_norm(clfs,X,Y):\n",
    "    X = StandardScaler().fit(X).transform(X)\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    for i in clfs:\n",
    "        clf = clfs[i]\n",
    "        print(\"\\n\\n======= {0} =======\".format(i))\n",
    "        start_time = time.time()\n",
    "        cv_acc = cross_val_score(clf, X, Y, cv=kf)\n",
    "        print('\\nTemps d\\'exécution d\\'un cross val : %s secondes'%(time.time() - start_time))\n",
    "        cv_auc = cross_val_score(clf, X, Y, cv=kf, scoring='roc_auc')\n",
    "        cv_prec = cross_val_score(clf, X, Y, cv=kf, scoring='precision')\n",
    "        print(\"Accuracy for {0} is: {1:.3f} +/- {2:.3f}\".format(i, np.mean(cv_acc), np.std(cv_acc)))\n",
    "        print(\"AUC for {0} is: {1:.3f} +/- {2:.3f}\".format(i, cv_auc.mean(), cv_auc.std()))\n",
    "        print(\"precision for {0} is: {1:.3f} +/- {2:.3f}\".format(i, cv_prec.mean(), cv_prec.std()))\n",
    "        \n",
    "run_classifiers_norm(clfs, X2_num, Y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une normalisation standard n'améliore pas les méthodes ensemblistes qui se basent sur des arbres de classification (RF, bagging et adaboost). Cependant, cela améliore l'AUC des techniques utilisant les différentes variables en même temps dans l'agorithme comme les KPPV ou le MLP. L'AUC du KPPV passe alors de 0.725 à 0.804."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 : Traitement sur les données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Variables caracteristiques\n",
    "X3 = values[:,:-1]\n",
    "# Labels a predire\n",
    "Y3 = values[:,-1]\n",
    "Y3[Y3 == '+'] = 1\n",
    "Y3[Y3 == '-'] = 0\n",
    "Y3 = Y3.astype(float)\n",
    "\n",
    "# Colonnes categorielles et numériques\n",
    "col_cat = (0,3,4,5,6,8,9,11,12)\n",
    "col_num = (1,2,7,10,13,14)\n",
    "X_cat = np.copy(X3[:, col_cat])\n",
    "X_cat = X_cat.astype(str)\n",
    "\n",
    "# Variables categorielles\n",
    "for col_id in range(len(col_cat)):\n",
    "    unique_val, val_idx = np.unique(X_cat[:, col_id], return_inverse=True)\n",
    "    X_cat[:, col_id] = val_idx\n",
    "imp_cat = Imputer(missing_values=0, strategy='most_frequent')\n",
    "X_cat[:, range(5)] = imp_cat.fit_transform(X_cat[:, range(5)])\n",
    "\n",
    "# Variables numériques\n",
    "X_num = np.copy(X3[:, col_num])\n",
    "X_num[X_num == '?'] = np.nan\n",
    "X_num = X_num.astype(float)\n",
    "imp_num = Imputer(missing_values=np.nan, strategy='mean')\n",
    "X_num = imp_num.fit_transform(X_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# On encode les variables categorielles\n",
    "X_cat_bin = OneHotEncoder().fit_transform(X_cat).toarray()\n",
    "X_num_norm = StandardScaler().fit(X_num).transform(X_num)\n",
    "\n",
    "# Jeu de données final\n",
    "X_proc = np.hstack((X_cat_bin, X_num_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= MLP =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 9.610473155975342 secondes\n",
      "Accuracy for MLP is: 0.818 +/- 0.053\n",
      "AUC for MLP is: 0.853 +/- 0.045\n",
      "precision for MLP is: 0.804 +/- 0.099\n",
      "\n",
      "\n",
      "======= ID3 =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.15278959274291992 secondes\n",
      "Accuracy for ID3 is: 0.804 +/- 0.039\n",
      "AUC for ID3 is: 0.797 +/- 0.038\n",
      "precision for ID3 is: 0.793 +/- 0.093\n",
      "\n",
      "\n",
      "======= ADABOOST =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 2.116410493850708 secondes\n",
      "Accuracy for ADABOOST is: 0.846 +/- 0.045\n",
      "AUC for ADABOOST is: 0.910 +/- 0.051\n",
      "precision for ADABOOST is: 0.814 +/- 0.063\n",
      "\n",
      "\n",
      "======= BAGGING =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 3.3180441856384277 secondes\n",
      "Accuracy for BAGGING is: 0.865 +/- 0.039\n",
      "AUC for BAGGING is: 0.913 +/- 0.049\n",
      "precision for BAGGING is: 0.842 +/- 0.081\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.1545276641845703 secondes\n",
      "Accuracy for KPPV is: 0.846 +/- 0.050\n",
      "AUC for KPPV is: 0.906 +/- 0.043\n",
      "precision for KPPV is: 0.846 +/- 0.098\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 1.3382036685943604 secondes\n",
      "Accuracy for RF is: 0.878 +/- 0.038\n",
      "AUC for RF is: 0.928 +/- 0.047\n",
      "precision for RF is: 0.850 +/- 0.070\n",
      "\n",
      "\n",
      "======= CART =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.09280705451965332 secondes\n",
      "Accuracy for CART is: 0.797 +/- 0.055\n",
      "AUC for CART is: 0.790 +/- 0.064\n",
      "precision for CART is: 0.764 +/- 0.076\n",
      "\n",
      "\n",
      "======= NB =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.046060800552368164 secondes\n",
      "Accuracy for NB is: 0.764 +/- 0.070\n",
      "AUC for NB is: 0.868 +/- 0.056\n",
      "precision for NB is: 0.868 +/- 0.081\n"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "run_classifiers(clfs, X_proc, Y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'apport de l'information des variables catégorielles augmente grandement la qualité de la classification. Si on regarde l'AUC ce sont toujours les classifieurs ensemblistes qui donnent les meilleurs résultats, avec le Random Forest en tête avec une AUC de 0.928 d'AUC. Le classifieur Bayésien reste cependant le classifieur qui donne la meilleurs précision de 0.868."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Apprentissage supervisé sur des données textuelles : Feature engineering et Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= MLP =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 21.15338945388794 secondes\n",
      "Accuracy for MLP is: 0.987 +/- 0.002\n",
      "AUC for MLP is: 0.984 +/- 0.010\n",
      "precision for MLP is: 0.980 +/- 0.014\n",
      "\n",
      "\n",
      "======= ID3 =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 4.25559663772583 secondes\n",
      "Accuracy for ID3 is: 0.971 +/- 0.007\n",
      "AUC for ID3 is: 0.922 +/- 0.025\n",
      "precision for ID3 is: 0.919 +/- 0.025\n",
      "\n",
      "\n",
      "======= ADABOOST =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 34.99478626251221 secondes\n",
      "Accuracy for ADABOOST is: 0.973 +/- 0.002\n",
      "AUC for ADABOOST is: 0.979 +/- 0.012\n",
      "precision for ADABOOST is: 0.946 +/- 0.024\n",
      "\n",
      "\n",
      "======= BAGGING =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 143.6916308403015 secondes\n",
      "Accuracy for BAGGING is: 0.976 +/- 0.007\n",
      "AUC for BAGGING is: 0.981 +/- 0.012\n",
      "precision for BAGGING is: 0.940 +/- 0.027\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 1.8782908916473389 secondes\n",
      "Accuracy for KPPV is: 0.912 +/- 0.011\n",
      "AUC for KPPV is: 0.855 +/- 0.023\n",
      "precision for KPPV is: 1.000 +/- 0.000\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 43.43914866447449 secondes\n",
      "Accuracy for RF is: 0.978 +/- 0.006\n",
      "AUC for RF is: 0.992 +/- 0.007\n",
      "precision for RF is: 0.998 +/- 0.005\n",
      "\n",
      "\n",
      "======= CART =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 5.238362073898315 secondes\n",
      "Accuracy for CART is: 0.970 +/- 0.009\n",
      "AUC for CART is: 0.926 +/- 0.029\n",
      "precision for CART is: 0.908 +/- 0.028\n",
      "\n",
      "\n",
      "======= NB =======\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-d6ac142aa8cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mXvectorized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mrun_classifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXvectorized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mYtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-85-f152a60de2ee>\u001b[0m in \u001b[0;36mrun_classifiers\u001b[0;34m(clfs, X, Y)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n======= {0} =======\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mcv_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTemps d\\'exécution d\\'un cross val : %s secondes'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcv_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m    192\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    745\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    510\u001b[0m                                       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m                                       \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                                       accept_large_sparse=accept_large_sparse)\n\u001b[0m\u001b[1;32m    513\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;31m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[1;32m    314\u001b[0m                         \u001b[0;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                         'convert to a dense numpy array.')\n",
      "\u001b[0;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "data3 = pd.read_csv('./SMSSpamCollection.data', sep='\\t', header = None)\n",
    "arraydata = data3.values\n",
    "\n",
    "# Variables et labels\n",
    "Xtxt = arraydata[:,1]\n",
    "Ytxt = arraydata[:,0]\n",
    "\n",
    "# Conversion du label\n",
    "Ytxt[Ytxt == 'ham'] = 0\n",
    "Ytxt[Ytxt == 'spam'] = 1\n",
    "Ytxt = Ytxt.astype(int)\n",
    "\n",
    "# On vectorise les sms\n",
    "vectorizer = CountVectorizer()\n",
    "Xvectorized = vectorizer.fit_transform(Xtxt)\n",
    "run_classifiers(X=Xvectorized, Y=Ytxt, clfs=clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que juste en vectorisant les sms, les résulats de classification sont très bon. Les techniques ensemblistes restent les meilleurs, principalement avec le modèle de Random Forest qui donne une AUC de 0.992 et une précision de 0.998. On remarque aussi que le classifieur Bayésien ne fonctionne pas avec les sparses matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= MLP =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 11.159014463424683 secondes\n",
      "Accuracy for MLP is: 0.984 +/- 0.004\n",
      "AUC for MLP is: 0.989 +/- 0.005\n",
      "precision for MLP is: 0.972 +/- 0.018\n",
      "\n",
      "\n",
      "======= ID3 =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 4.998236179351807 secondes\n",
      "Accuracy for ID3 is: 0.968 +/- 0.003\n",
      "AUC for ID3 is: 0.918 +/- 0.012\n",
      "precision for ID3 is: 0.901 +/- 0.005\n",
      "\n",
      "\n",
      "======= ADABOOST =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 24.2587628364563 secondes\n",
      "Accuracy for ADABOOST is: 0.972 +/- 0.002\n",
      "AUC for ADABOOST is: 0.972 +/- 0.008\n",
      "precision for ADABOOST is: 0.930 +/- 0.012\n",
      "\n",
      "\n",
      "======= BAGGING =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 89.84316778182983 secondes\n",
      "Accuracy for BAGGING is: 0.975 +/- 0.003\n",
      "AUC for BAGGING is: 0.982 +/- 0.009\n",
      "precision for BAGGING is: 0.945 +/- 0.012\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 1.5532004833221436 secondes\n",
      "Accuracy for KPPV is: 0.932 +/- 0.032\n",
      "AUC for KPPV is: 0.968 +/- 0.012\n",
      "precision for KPPV is: 0.996 +/- 0.005\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 18.36499047279358 secondes\n",
      "Accuracy for RF is: 0.975 +/- 0.004\n",
      "AUC for RF is: 0.992 +/- 0.004\n",
      "precision for RF is: 0.998 +/- 0.003\n",
      "\n",
      "\n",
      "======= CART =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 3.7133629322052 secondes\n",
      "Accuracy for CART is: 0.968 +/- 0.003\n",
      "AUC for CART is: 0.925 +/- 0.009\n",
      "precision for CART is: 0.892 +/- 0.017\n",
      "\n",
      "\n",
      "======= NB =======\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-8ee0242d5e56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mXtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmooth_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXvectorized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mrun_classifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXtfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mYtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-151-8ee0242d5e56>\u001b[0m in \u001b[0;36mrun_classifiers\u001b[0;34m(clfs, X, Y)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n======= {0} =======\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mcv_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTemps d\\'exécution d\\'un cross val : %s secondes'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcv_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m    192\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    745\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    510\u001b[0m                                       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m                                       \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                                       accept_large_sparse=accept_large_sparse)\n\u001b[0m\u001b[1;32m    513\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;31m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[1;32m    314\u001b[0m                         \u001b[0;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                         'convert to a dense numpy array.')\n",
      "\u001b[0;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "# On fait une validation croisée a k = 5 pour augmenter la rapidité\n",
    "def run_classifiers(clfs,X,Y):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    for i in clfs:\n",
    "        clf = clfs[i]\n",
    "        print(\"\\n\\n======= {0} =======\".format(i))\n",
    "        start_time = time.time()\n",
    "        cv_acc = cross_val_score(clf, X, Y, cv=kf)\n",
    "        print('\\nTemps d\\'exécution d\\'un cross val : %s secondes'%(time.time() - start_time))\n",
    "        cv_auc = cross_val_score(clf, X, Y, cv=kf, scoring='roc_auc')\n",
    "        cv_prec = cross_val_score(clf, X, Y, cv=kf, scoring='precision')\n",
    "        print(\"Accuracy for {0} is: {1:.3f} +/- {2:.3f}\".format(i, np.mean(cv_acc), np.std(cv_acc)))\n",
    "        print(\"AUC for {0} is: {1:.3f} +/- {2:.3f}\".format(i, cv_auc.mean(), cv_auc.std()))\n",
    "        print(\"precision for {0} is: {1:.3f} +/- {2:.3f}\".format(i, cv_prec.mean(), cv_prec.std()))\n",
    "\n",
    "\n",
    "Xtfidf = TfidfTransformer(smooth_idf=False).fit_transform(Xvectorized)\n",
    "run_classifiers(X=Xtfidf, Y=Ytxt, clfs=clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate qu'en rajoutant des poids donnant plus d'importance aux termes rares comparé aux termes souvent présents, les métriques évoluent differements selon les classifieurs. Par exemple cela a augmenté l'AUC du MLP de 0.984 à 0.989, mais a diminué sa précision de 0.980 à 0.972. Pour l'ADABOOST, cela a diminué l'AUC de 0.979 à 0.972 et la précision de 0.948 à 0.930."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= MLP =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 16.58793544769287 secondes\n",
      "Accuracy for MLP is: 0.973 +/- 0.003\n",
      "AUC for MLP is: 0.987 +/- 0.005\n",
      "precision for MLP is: 0.890 +/- 0.018\n",
      "\n",
      "\n",
      "======= ID3 =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 6.809550523757935 secondes\n",
      "Accuracy for ID3 is: 0.953 +/- 0.001\n",
      "AUC for ID3 is: 0.909 +/- 0.009\n",
      "precision for ID3 is: 0.812 +/- 0.025\n",
      "\n",
      "\n",
      "======= ADABOOST =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 32.357205390930176 secondes\n",
      "Accuracy for ADABOOST is: 0.972 +/- 0.006\n",
      "AUC for ADABOOST is: 0.981 +/- 0.003\n",
      "precision for ADABOOST is: 0.920 +/- 0.032\n",
      "\n",
      "\n",
      "======= BAGGING =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 168.47836565971375 secondes\n",
      "Accuracy for BAGGING is: 0.973 +/- 0.005\n",
      "AUC for BAGGING is: 0.973 +/- 0.006\n",
      "precision for BAGGING is: 0.960 +/- 0.010\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 13.758306741714478 secondes\n",
      "Accuracy for KPPV is: 0.968 +/- 0.007\n",
      "AUC for KPPV is: 0.966 +/- 0.013\n",
      "precision for KPPV is: 0.963 +/- 0.030\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 16.525413751602173 secondes\n",
      "Accuracy for RF is: 0.974 +/- 0.004\n",
      "AUC for RF is: 0.975 +/- 0.009\n",
      "precision for RF is: 0.986 +/- 0.009\n",
      "\n",
      "\n",
      "======= CART =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 5.491069078445435 secondes\n",
      "Accuracy for CART is: 0.950 +/- 0.004\n",
      "AUC for CART is: 0.906 +/- 0.012\n",
      "precision for CART is: 0.798 +/- 0.036\n",
      "\n",
      "\n",
      "======= NB =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.06766796112060547 secondes\n",
      "Accuracy for NB is: 0.826 +/- 0.008\n",
      "AUC for NB is: 0.928 +/- 0.011\n",
      "precision for NB is: 0.427 +/- 0.021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, n_iter=7, random_state=1)\n",
    "Xtrunc = svd.fit_transform(Xtfidf)\n",
    "\n",
    "run_classifiers(X=Xtrunc, Y=Ytxt, clfs=clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que passer des sparses matrix à un array réduit par indexation sémantique diminue la qualité de la classification. Par exemple, l'AUC de la random forest passe de 0.992 à 0.975. Cela doit venir du parametre n_components qui indique le nombre de dimensions à utiliser. On va essayer d'augmenter ce paramètre sur les randoms forests et un classifieur Bayésien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= NB =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.168809175491333 secondes\n",
      "Accuracy for NB is: 0.871 +/- 0.005\n",
      "AUC for NB is: 0.949 +/- 0.008\n",
      "precision for NB is: 0.510 +/- 0.024\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 25.9538311958313 secondes\n",
      "Accuracy for RF is: 0.970 +/- 0.003\n",
      "AUC for RF is: 0.974 +/- 0.011\n",
      "precision for RF is: 0.992 +/- 0.007\n"
     ]
    }
   ],
   "source": [
    "clfs2 = {\n",
    "'NB': GaussianNB(),\n",
    "'RF': RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "}\n",
    "\n",
    "svd = TruncatedSVD(n_components=200, n_iter=7, random_state=1)\n",
    "Xtrunc = svd.fit_transform(Xtfidf)\n",
    "\n",
    "run_classifiers(X=Xtrunc, Y=Ytxt, clfs=clfs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmenter le nombre de dimensions à 200 ne change pas beaucoup l'AUC du random forest (0.975 à 0.974) mais augmente la précision 0.986 de 0.992. Cependant, les résultats de la classification restent plus bas que juste avec la vectorisation des chaines de caractères. La réduction des dimensions du jeu de données fait sans doute perdre de l'information ce qui baisse la qualité de la prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline de traitement de texte pour la classification\n",
    "pipeline = Pipeline([\n",
    "    ('Vectorize', CountVectorizer()),\n",
    "    ('Weights', TfidfTransformer(smooth_idf=False)),\n",
    "    ('Truncation', TruncatedSVD(n_components=4, n_iter=7, random_state=1))])\n",
    "\n",
    "# Nouveau jeu de données\n",
    "DF = pd.read_csv('./yelp-text-by-stars.csv', sep=';', engine='python')\n",
    "arraydata2 = DF.values\n",
    "\n",
    "# Variables et labels\n",
    "Xyelp = arraydata2[:,1]\n",
    "Yyelp = arraydata2[:,0]\n",
    "Yyelp = Yyelp.astype(int)\n",
    "\n",
    "# Traitement des données de texte\n",
    "Xprocessed = pipeline.fit_transform(Xyelp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= MLP =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 69.59812831878662 secondes\n",
      "Accuracy for MLP is: 0.489 +/- 0.003\n",
      "\n",
      "\n",
      "======= ID3 =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 6.492163896560669 secondes\n",
      "Accuracy for ID3 is: 0.372 +/- 0.004\n",
      "\n",
      "\n",
      "======= ADABOOST =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 13.109768152236938 secondes\n",
      "Accuracy for ADABOOST is: 0.481 +/- 0.003\n",
      "\n",
      "\n",
      "======= BAGGING =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 75.81055498123169 secondes\n",
      "Accuracy for BAGGING is: 0.449 +/- 0.004\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 1.444054126739502 secondes\n",
      "Accuracy for KPPV is: 0.433 +/- 0.001\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 36.187769412994385 secondes\n",
      "Accuracy for RF is: 0.454 +/- 0.003\n",
      "\n",
      "\n",
      "======= CART =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 2.0903873443603516 secondes\n",
      "Accuracy for CART is: 0.372 +/- 0.002\n",
      "\n",
      "\n",
      "======= NB =======\n",
      "\n",
      "Temps d'exécution d'un cross val : 0.1092081069946289 secondes\n",
      "Accuracy for NB is: 0.473 +/- 0.003\n"
     ]
    }
   ],
   "source": [
    "# On calcule seulement l'accuracy ici etant donné que c'est du multilabel (+reduit le temps de calcul)\n",
    "def run_classifiers_acc(clfs,X,Y):\n",
    "    X = StandardScaler().fit(X).transform(X)\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "    for i in clfs:\n",
    "        clf = clfs[i]\n",
    "        print(\"\\n\\n======= {0} =======\".format(i))\n",
    "        start_time = time.time()\n",
    "        cv_acc = cross_val_score(clf, X, Y, cv=kf)\n",
    "        print('\\nTemps d\\'exécution d\\'un cross val : %s secondes'%(time.time() - start_time))\n",
    "        print(\"Accuracy for {0} is: {1:.3f} +/- {2:.3f}\".format(i, np.mean(cv_acc), np.std(cv_acc)))\n",
    "\n",
    "run_classifiers_acc(X=Xprocessed, Y=Yyelp, clfs=clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que l'accuracy des différents modèle est relativement basse, avec un maximum de 0.489 pour le MLP. Les mathodes ensemblistes marchent presque aussi bien tout comme le Naive Bayesian classifieur (0.473). Ces scores bien plus bas que les précédents proviennent tout d'abord d'un nombre de dimensions choisi  bas  lors de la réduction des dimensions (4). Avec plus de temps, il faudrait essayer une valeur plus grand de ce paramètre. Cela prend du temps de tester plusieurs combinaisons avec plusieurs modèles, le jeu de données étant très grand.\n",
    "De plus, contrairement aux précédents, ce jeu est multilabels avec 5 valeurs possibles, ce qui complique grandement la tache de classification comme on peut le voir sur les résultats."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
